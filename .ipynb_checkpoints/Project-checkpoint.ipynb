{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698f96e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nii_object = nib.load('Data/I004_3.nii.gz')\n",
    "nii_data = nii_object.get_fdata()\n",
    "\n",
    "# print(nii_object)\n",
    "print(nii_data)\n",
    "\n",
    "# def show_slices(slices):\n",
    "#     fig, axes = plt.subplots(1,len(slices))\n",
    "#     for i, slice in enumerate(slices):\n",
    "#         axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "# slice_0 = nii_data[int(nii_data.shape[0]/2), :, :]\n",
    "# slice_1 = nii_data[:,int(nii_data.shape[1]/2), :]\n",
    "# slice_2 = nii_data[:, :, int(nii_data.shape[2]/2)]\n",
    "# slice_3 = nii_data[:,:,3]\n",
    "# show_slices([slice_0, slice_1, slice_2,slice_3])\n",
    "# plt.suptitle(\"Center slices for EPI image\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca652ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def read(path):\n",
    "    scan = nib.load(path)\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "# normalizing the volume between the ranges of [-1000,1000]\n",
    "def normalize(volume):\n",
    "    min = -1000\n",
    "    max = 1000\n",
    "    volume[volume < min] = min\n",
    "    volume[volume < max] = max\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume \n",
    "\n",
    "# to lower computational cost, resize the 3D image across the z axis\n",
    "def resize(img):\n",
    "    \n",
    "    setDepth = 64\n",
    "    setWidth = 128\n",
    "    setHeight = 128\n",
    "\n",
    "    currentDepth = img.shape[2]\n",
    "    currentWidth = img.shape[1]\n",
    "    currentHeight = img.shape[0]\n",
    "\n",
    "    d = currentDepth / setDepth\n",
    "    w = currentWidth / setWidth\n",
    "    h  = currentHeight / setHeight\n",
    "\n",
    "    depthFactor = 1 / d \n",
    "    widthFactor = 1 / w \n",
    "    heightFactor = 1 / h\n",
    "    \n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    img  = ndimage.zoom(img, (widthFactor, heightFactor, depthFactor))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_img(path):\n",
    "    volume = read(path)\n",
    "    volume = normalize(volume)\n",
    "    volume = resize(volume)\n",
    "    return volume \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1544361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n",
      "106\n",
      "112\n",
      "80\n",
      "707\n",
      "707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3440/3739210714.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  non_target_imgs = np.array([process_img(path) for path in non_target_paths])\n"
     ]
    }
   ],
   "source": [
    "# Creating np.arrays for the 3D images and their respective ground truth\n",
    "\n",
    "#Creating the paths for these images\n",
    "non_target_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/0\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/0\")\n",
    "]\n",
    "saline_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/1\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/1\")\n",
    "]\n",
    "rubber_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/2\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/2\")\n",
    "]\n",
    "clay_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/3\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/3\")\n",
    "]\n",
    "\n",
    "print(len(non_target_paths))\n",
    "print(len(saline_paths))\n",
    "print(len(rubber_paths))\n",
    "print(len(clay_paths))\n",
    "\n",
    "# Creating np.array for respective images feature\n",
    "\n",
    "non_target_imgs = np.array([process_img(path) for path in non_target_paths])\n",
    "saline_imgs = np.array([process_img(path) for path in saline_paths])\n",
    "rubber_imgs = np.array([process_img(path) for path in rubber_paths])\n",
    "clay_imgs = np.array([process_img(path) for path in clay_paths])\n",
    "\n",
    "# now we are assigning their respective ground truth\n",
    "\n",
    "print(len(non_target_imgs))\n",
    "print(len(non_target_paths))\n",
    "\n",
    "# non_target = np.array([0 for _ in range(len())])\n",
    "# saline_target = \n",
    "# rubber_target = \n",
    "# clay_target = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e12d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
