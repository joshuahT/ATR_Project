{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0698f96e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "nii_object = nib.load('Data/I004_3.nii.gz')\n",
    "nii_data = nii_object.get_fdata()\n",
    "\n",
    "# print(nii_object)\n",
    "print(nii_data)\n",
    "\n",
    "# def show_slices(slices):\n",
    "#     fig, axes = plt.subplots(1,len(slices))\n",
    "#     for i, slice in enumerate(slices):\n",
    "#         axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "# slice_0 = nii_data[int(nii_data.shape[0]/2), :, :]\n",
    "# slice_1 = nii_data[:,int(nii_data.shape[1]/2), :]\n",
    "# slice_2 = nii_data[:, :, int(nii_data.shape[2]/2)]\n",
    "# slice_3 = nii_data[:,:,3]\n",
    "# show_slices([slice_0, slice_1, slice_2,slice_3])\n",
    "# plt.suptitle(\"Center slices for EPI image\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59096993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bca652ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def read(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "                                            # image shapes were not returning correctly\n",
    "# def read(path):\n",
    "#     scan = nib.load(path)\n",
    "#     scan = scan.get_fdata()\n",
    "#     return scan\n",
    "\n",
    "# # normalizing the volume between the ranges of [-1000,1000]\n",
    "# def normalize(volume):\n",
    "#     min = -1000\n",
    "#     max = 1000\n",
    "#     volume[volume < min] = min\n",
    "#     volume[volume < max] = max\n",
    "#     volume = volume.astype(\"float32\")\n",
    "#     return volume \n",
    "\n",
    "# # to lower computational cost, resize the 3D image across the z axis\n",
    "# def resize(img):\n",
    "    \n",
    "#     setDepth = 64\n",
    "#     setWidth = 128\n",
    "#     setHeight = 128\n",
    "\n",
    "#     currentDepth = img.shape[2]\n",
    "#     currentWidth = img.shape[1]\n",
    "#     currentHeight = img.shape[0]\n",
    "\n",
    "#     d = currentDepth / setDepth\n",
    "#     w = currentWidth / setWidth\n",
    "#     h  = currentHeight / setHeight\n",
    "\n",
    "#     depthFactor = 1 / d \n",
    "#     widthFactor = 1 / w \n",
    "#     heightFactor = 1 / h\n",
    "    \n",
    "#     img = ndimage.rotate(img, 90, reshape=False)\n",
    "#     img  = ndimage.zoom(img, (widthFactor, heightFactor, depthFactor), order=1)\n",
    "\n",
    "#     return img\n",
    "\n",
    "\n",
    "def process_img(path):\n",
    "    volume = read(path)\n",
    "    volume = normalize(volume)\n",
    "    volume = resize(volume)\n",
    "    return volume \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1544361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (707,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 28\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(non_target_paths))\n\u001b[0;32m     22\u001b[0m \u001b[39m# print(len(saline_paths))\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# print(len(rubber_paths))\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m# print(len(clay_paths))\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[39m# # Creating np.array for respective images feature\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m non_target_imgs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([process_img(path) \u001b[39mfor\u001b[39;49;00m path \u001b[39min\u001b[39;49;00m non_target_paths])\n\u001b[0;32m     29\u001b[0m \u001b[39m# saline_imgs = np.array([process_img(path) for path in saline_paths])\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# rubber_imgs = np.array([process_img(path) for path in rubber_paths])\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# clay_imgs = np.array([process_img(path) for path in clay_paths])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39m# rubber_target = np.array([2 for _ in range(len(rubber_imgs))])\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m# clay_target = np.array([3 for _ in range(len(clay_imgs))])\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (707,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# # Creating np.arrays for the 3D images and their respective ground truth\n",
    "\n",
    "# #Creating the paths for these images\n",
    "non_target_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/0\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/0\")\n",
    "]\n",
    "# saline_paths = [\n",
    "#     os.path.join(os.getcwd(), \"labeled_data/data/1\", x)\n",
    "#     for x in os.listdir(\"labeled_data/data/1\")\n",
    "# ]\n",
    "# rubber_paths = [\n",
    "#     os.path.join(os.getcwd(), \"labeled_data/data/2\", x)\n",
    "#     for x in os.listdir(\"labeled_data/data/2\")\n",
    "# ]\n",
    "# clay_paths = [\n",
    "#     os.path.join(os.getcwd(), \"labeled_data/data/3\", x)\n",
    "#     for x in os.listdir(\"labeled_data/data/3\")\n",
    "# ]\n",
    "\n",
    "print(len(non_target_paths))\n",
    "# print(len(saline_paths))\n",
    "# print(len(rubber_paths))\n",
    "# print(len(clay_paths))\n",
    "\n",
    "# # Creating np.array for respective images feature\n",
    "\n",
    "non_target_imgs = np.array([process_img(path) for path in non_target_paths])\n",
    "# saline_imgs = np.array([process_img(path) for path in saline_paths])\n",
    "# rubber_imgs = np.array([process_img(path) for path in rubber_paths])\n",
    "# clay_imgs = np.array([process_img(path) for path in clay_paths])\n",
    "\n",
    "# # now we are assigning their respective ground truth\n",
    "\n",
    "# non_target = np.array([0 for _ in range(len(non_target_imgs))])\n",
    "# saline_target = np.array([1 for _ in range(len(saline_imgs))])\n",
    "# rubber_target = np.array([2 for _ in range(len(rubber_imgs))])\n",
    "# clay_target = np.array([3 for _ in range(len(clay_imgs))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(non_target_imgs[0].m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9b215cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pjame\\OneDrive\\Documents\\GitHub\\ATR_Project\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Y)\n\u001b[1;32m---> 19\u001b[0m np\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39mX.npy\u001b[39;49m\u001b[39m'\u001b[39;49m, X)\n\u001b[0;32m     20\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mY.npy\u001b[39m\u001b[39m'\u001b[39m, Y)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pjame\\.conda\\envs\\tf\\lib\\site-packages\\numpy\\lib\\npyio.py:522\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[0;32m    521\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    523\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[1;32mc:\\Users\\pjame\\.conda\\envs\\tf\\lib\\site-packages\\numpy\\lib\\format.py:711\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[39mif\u001b[39;00m pickle_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m         pickle_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 711\u001b[0m     pickle\u001b[39m.\u001b[39mdump(array, fp, protocol\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_kwargs)\n\u001b[0;32m    712\u001b[0m \u001b[39melif\u001b[39;00m array\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m array\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous:\n\u001b[0;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "data_folder = f'{os.getcwd()}/labeled_data/data/'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for label in os.listdir(data_folder):\n",
    "    img_directory = f'{data_folder}/{label}/'\n",
    "    for img in os.listdir(img_directory):\n",
    "        X.append(process_img(img_directory + '/' + img)) \n",
    "        Y += [label]\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "X = np.array(X, dtype='object')\n",
    "Y = np.array(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9774f126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005, 128, 128, 64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddf7fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "# test = x_train[0].flatten()\n",
    "# print(test.shape)\n",
    "\n",
    "# test1 = np.asarray(x_train)\n",
    "# test2 = np.asarray(y_train)\n",
    "# test1 = tf.convert_to_tensor(x_train)\n",
    "train_loader = tf.data.Dataset.from_tensor_slices(x_train, y_train)\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081817d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2796f898c241be261d17d4440712f4c58a6e72713839fe7ec4d10cc08aa00573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
