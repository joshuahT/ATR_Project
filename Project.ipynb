{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0698f96e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/jp/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: cusparseSpSM_analysis, version libcusparse.so.11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7966/294229470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnii_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/I004_3.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnii_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnii_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/jp/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: cusparseSpSM_analysis, version libcusparse.so.11"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "nii_object = nib.load('Data/I004_3.nii.gz')\n",
    "nii_data = nii_object.get_fdata()\n",
    "\n",
    "# print(nii_object)\n",
    "print(nii_data)\n",
    "\n",
    "# def show_slices(slices):\n",
    "#     fig, axes = plt.subplots(1,len(slices))\n",
    "#     for i, slice in enumerate(slices):\n",
    "#         axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "# slice_0 = nii_data[int(nii_data.shape[0]/2), :, :]\n",
    "# slice_1 = nii_data[:,int(nii_data.shape[1]/2), :]\n",
    "# slice_2 = nii_data[:, :, int(nii_data.shape[2]/2)]\n",
    "# slice_3 = nii_data[:,:,3]\n",
    "# show_slices([slice_0, slice_1, slice_2,slice_3])\n",
    "# plt.suptitle(\"Center slices for EPI image\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca652ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:32:12.177373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 16:32:12.332819: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-27 16:32:12.336316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-27 16:32:12.336332: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-27 16:32:13.057061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 16:32:13.057162: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 16:32:13.057169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def read(path):\n",
    "    scan = nib.load(path)\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "# normalizing the volume between the ranges of [-1000,1000]\n",
    "def normalize(volume):\n",
    "    min = -1000\n",
    "    max = 1000\n",
    "    volume[volume < min] = min\n",
    "    volume[volume < max] = max\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume \n",
    "\n",
    "# to lower computational cost, resize the 3D image across the z axis\n",
    "def resize(img):\n",
    "    \n",
    "    setDepth = 64\n",
    "    setWidth = 128\n",
    "    setHeight = 128\n",
    "\n",
    "    currentDepth = img.shape[2]\n",
    "    currentWidth = img.shape[1]\n",
    "    currentHeight = img.shape[0]\n",
    "\n",
    "    d = currentDepth / setDepth\n",
    "    w = currentWidth / setWidth\n",
    "    h  = currentHeight / setHeight\n",
    "\n",
    "    depthFactor = 1 / d \n",
    "    widthFactor = 1 / w \n",
    "    heightFactor = 1 / h\n",
    "    \n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    img  = ndimage.zoom(img, (widthFactor, heightFactor, depthFactor))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_img(path):\n",
    "    volume = read(path)\n",
    "    volume = normalize(volume)\n",
    "    volume = resize(volume)\n",
    "    return volume \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating np.arrays for the 3D images and their respective ground truth\n",
    "\n",
    "#Creating the paths for these images\n",
    "non_target_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/0\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/0\")\n",
    "]\n",
    "saline_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/1\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/1\")\n",
    "]\n",
    "rubber_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/2\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/2\")\n",
    "]\n",
    "clay_paths = [\n",
    "    os.path.join(os.getcwd(), \"labeled_data/data/3\", x)\n",
    "    for x in os.listdir(\"labeled_data/data/3\")\n",
    "]\n",
    "\n",
    "print(len(non_target_paths))\n",
    "print(len(saline_paths))\n",
    "print(len(rubber_paths))\n",
    "print(len(clay_paths))\n",
    "\n",
    "# Creating np.array for respective images feature\n",
    "\n",
    "non_target_imgs = np.array([process_img(path) for path in non_target_paths])\n",
    "saline_imgs = np.array([process_img(path) for path in saline_paths])\n",
    "rubber_imgs = np.array([process_img(path) for path in rubber_paths])\n",
    "clay_imgs = np.array([process_img(path) for path in clay_paths])\n",
    "\n",
    "# now we are assigning their respective ground truth\n",
    "\n",
    "non_target = np.array([0 for _ in range(len(non_target_imgs))])\n",
    "saline_target = np.array([1 for _ in range(len(saline_imgs))])\n",
    "rubber_target = np.array([2 for _ in range(len(rubber_imgs))])\n",
    "clay_target = np.array([3 for _ in range(len(clay_imgs))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9b215cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jp/Documents/GitHub/ATR_Project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "data_folder = f'{os.getcwd()}/labeled_data/data/'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for label in os.listdir(data_folder):\n",
    "    img_directory = f'{data_folder}/{label}/'\n",
    "    for img in os.listdir(img_directory):\n",
    "        X += [process_img(f'{img_directory}/{img}')]\n",
    "        Y += [label]\n",
    "        \n",
    "        \n",
    "X = np.array(X, dtype='object')\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddf7fc30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7966/2240442545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# train_loader = tf.data.Dataset.from_tensor_slices(test1, test2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# validation_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "test1 = np.asarray(x_train)\n",
    "test2 = np.asarray(y_train)\n",
    "test1 = tf.convert_to_tensor(x_train)\n",
    "# train_loader = tf.data.Dataset.from_tensor_slices(test1, test2)\n",
    "# validation_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2796f898c241be261d17d4440712f4c58a6e72713839fe7ec4d10cc08aa00573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
